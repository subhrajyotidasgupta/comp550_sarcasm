{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Fetch and Load Data"
      ],
      "metadata": {
        "id": "ng5nmxsUzmwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/train.En.csv')\n",
        "df_test = pd.read_csv('/content/task_B_En_test.csv')\n",
        "df_train = df\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "wxJUh0jJCOSs",
        "outputId": "1292e21f-21e1-4668-87f1-47329122ecd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                              tweet  sarcastic  \\\n",
              "0           0  The only thing I got from college is a caffein...          1   \n",
              "1           1  I love it when professors draw a big question ...          1   \n",
              "2           2  Remember the hundred emails from companies whe...          1   \n",
              "3           3  Today my pop-pop told me I was not “forced” to...          1   \n",
              "4           4  @VolphanCarol @littlewhitty @mysticalmanatee I...          1   \n",
              "\n",
              "                                            rephrase  sarcasm  irony  satire  \\\n",
              "0  College is really difficult, expensive, tiring...      0.0    1.0     0.0   \n",
              "1  I do not like when professors don’t write out ...      1.0    0.0     0.0   \n",
              "2  I, at the bare minimum, wish companies actuall...      0.0    1.0     0.0   \n",
              "3  Today my pop-pop told me I was not \"forced\" to...      1.0    0.0     0.0   \n",
              "4  I would say Ted Cruz is an asshole and doesn’t...      1.0    0.0     0.0   \n",
              "\n",
              "   understatement  overstatement  rhetorical_question  \n",
              "0             0.0            0.0                  0.0  \n",
              "1             0.0            0.0                  0.0  \n",
              "2             0.0            0.0                  0.0  \n",
              "3             0.0            0.0                  0.0  \n",
              "4             0.0            0.0                  0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-720fbc34-cf76-4680-8ec3-690103374c6e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet</th>\n",
              "      <th>sarcastic</th>\n",
              "      <th>rephrase</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>irony</th>\n",
              "      <th>satire</th>\n",
              "      <th>understatement</th>\n",
              "      <th>overstatement</th>\n",
              "      <th>rhetorical_question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>The only thing I got from college is a caffein...</td>\n",
              "      <td>1</td>\n",
              "      <td>College is really difficult, expensive, tiring...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>I love it when professors draw a big question ...</td>\n",
              "      <td>1</td>\n",
              "      <td>I do not like when professors don’t write out ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Remember the hundred emails from companies whe...</td>\n",
              "      <td>1</td>\n",
              "      <td>I, at the bare minimum, wish companies actuall...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
              "      <td>1</td>\n",
              "      <td>Today my pop-pop told me I was not \"forced\" to...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
              "      <td>1</td>\n",
              "      <td>I would say Ted Cruz is an asshole and doesn’t...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-720fbc34-cf76-4680-8ec3-690103374c6e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-720fbc34-cf76-4680-8ec3-690103374c6e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-720fbc34-cf76-4680-8ec3-690103374c6e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.dropna(subset=['tweet'])\n",
        "df_test=df_test.dropna(subset=['text'])"
      ],
      "metadata": {
        "id": "kFbRkv0KCph7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OMkoTBWH2Qt",
        "outputId": "b639bd1d-c850-4f14-ce42-bcd2988e9b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34670"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df[df['sarcastic']==1].values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1zjh69hHsf3",
        "outputId": "7ab17105-6567-4ca8-ca11-1d0439bf3bb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "867"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0, 2, 2])\n",
        "ax.bar(['sarcastic', 'non-sarcastic'],\n",
        "       [len(df[df['sarcastic']==1].values), len(df[df['sarcastic']==0].values)])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N5wLsZW5Hdoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sarcasm=df['sarcasm'].sum()\n",
        "irony=df['irony'].sum()\n",
        "satire=df['satire'].sum()\n",
        "understatement=df['understatement'].sum()\n",
        "overstatement=df['overstatement'].sum()\n",
        "rhetorical_question=df['rhetorical_question'].sum()\n",
        "\n",
        "label_names = ['sarcasm', 'irony','satire', 'understatement','overstatement', 'rhetorical_question']\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1.5,1.5])\n",
        "students = [sarcasm,irony,satire,understatement,overstatement,rhetorical_question]\n",
        "ax.bar(label_names,students)\n",
        "plt.show()\n",
        "print(sarcasm,irony,satire,understatement,overstatement,rhetorical_question)"
      ],
      "metadata": {
        "id": "bWiELCJyD9wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "import nltk\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from bs4 import BeautifulSoup\n",
        "import re,string,unicodedata\n",
        "from keras.preprocessing import text, sequence\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from string import punctuation\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,LSTM,Dropout,Bidirectional,GRU\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "3c7uzfZoCUvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tokenization**"
      ],
      "metadata": {
        "id": "WhnuxFIHDYlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNvyIrn-Dj6c",
        "outputId": "8eca7fea-e065-4583-8dd5-33a0988cce1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = df['tweet'].apply(lambda x: ' '.join([val for val in word_tokenize(x.lower()) if val not in stop_words])).values\n",
        "tokens_test = df_test['text'].apply(lambda x: ' '.join([val for val in word_tokenize(x.lower()) if val not in stop_words])).values"
      ],
      "metadata": {
        "id": "FIg54O87Cz4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **TFIDF and Count Vectorizer**"
      ],
      "metadata": {
        "id": "PrnQeW4oEDJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "bow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
        "xtrain_bow = bow_vectorizer.fit_transform(tokens)\n",
        "xtest_bow = bow_vectorizer.transform(tokens_test)\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
        "xtrain_tfidf = tfidf_vectorizer.fit_transform(tokens)\n",
        "xtest_tfidf= tfidf_vectorizer.transform(tokens_test)"
      ],
      "metadata": {
        "id": "LNa1M-BFDd1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Word2Vec**"
      ],
      "metadata": {
        "id": "jjPdVYb4EZf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = [val.split() for val in tokens]\n",
        "tokens_test = [val.split() for val in tokens_test]"
      ],
      "metadata": {
        "id": "eOSvdUzTESLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "w2v_model = gensim.models.Word2Vec(\n",
        "            tokens,\n",
        "            vector_size=300,\n",
        "            window=5,\n",
        "            min_count=0,\n",
        "            sg=1,\n",
        "            hs=0,\n",
        "            negative=10,\n",
        "            seed=42)\n",
        "\n",
        "w2v_model.train(tokens, total_examples= len(tokens), epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCwlWId5EcXx",
        "outputId": "90264c1a-edde-499b-9930-43f14890b11d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1184743, 1376250)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.init_sims(replace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6STX_SF1Ee22",
        "outputId": "83c44ee8-c560-45ac-9a14-f06f11803dc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-c7757d71a30b>:1: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
            "  w2v_model.init_sims(replace=True)\n",
            "WARNING:gensim.models.keyedvectors:destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = set(w2v_model.wv.index_to_key)\n",
        "xtrain_w2v = np.array([np.mean(np.nan_to_num(np.array([w2v_model.wv[i] if i in words else np.zeros((300,)) for i in ls], dtype=object)), axis=0)\n",
        "                         for ls in tokens], dtype=object)\n",
        "xtest_w2v = np.array([np.mean(np.nan_to_num(np.array([w2v_model.wv[i] if i in words else np.zeros((300,)) for i in ls ], dtype=object)), axis=0)\n",
        "                         for ls in tokens_test], dtype=object)"
      ],
      "metadata": {
        "id": "nr-PRrjVElWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **GloVe**"
      ],
      "metadata": {
        "id": "tK2wWi4XFaet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
        "!unzip glove.twitter.27B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8IBAORsFDaZ",
        "outputId": "f92d41ff-0d41-4322-feb9-21e7329232e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-03 21:48:15--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip [following]\n",
            "--2023-04-03 21:48:15--  https://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1520408563 (1.4G) [application/zip]\n",
            "Saving to: ‘glove.twitter.27B.zip’\n",
            "\n",
            "glove.twitter.27B.z 100%[===================>]   1.42G  5.02MB/s    in 4m 45s  \n",
            "\n",
            "2023-04-03 21:53:00 (5.09 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n",
            "\n",
            "Archive:  glove.twitter.27B.zip\n",
            "  inflating: glove.twitter.27B.25d.txt  \n",
            "  inflating: glove.twitter.27B.50d.txt  \n",
            "  inflating: glove.twitter.27B.100d.txt  \n",
            "  inflating: glove.twitter.27B.200d.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_FILE = './glove.twitter.27B.200d.txt'\n",
        "def get_coefs(word, *arr):\n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))"
      ],
      "metadata": {
        "id": "UiZ-J9tVFiaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = df['tweet'].values\n",
        "x_test = df_test['text'].values"
      ],
      "metadata": {
        "id": "RngwttRSFk7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 35000\n",
        "maxlen = 200\n",
        "\n",
        "from keras.utils import pad_sequences\n",
        "\n",
        "tokenizer = text.Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "tokenized_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_train = pad_sequences(tokenized_train, maxlen=maxlen)\n",
        "\n",
        "tokenized_test = tokenizer.texts_to_sequences(x_test)\n",
        "X_test = pad_sequences(tokenized_test, maxlen=maxlen)"
      ],
      "metadata": {
        "id": "kpWCHT2XFn1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "embed_size = all_embs.shape[1]\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "#change below line if computing normal stats is too slow\n",
        "embedding_matrix = embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG3pdkvhFqBO",
        "outputId": "64f2fc3a-ff99-4682-efd7-cbe3992f95fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py:3473: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if (await self.run_code(code, result,  async_=asy)):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Machine Learning Methods**"
      ],
      "metadata": {
        "id": "kqwgwdALGBmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = df[['sarcasm', 'irony', 'satire', 'understatement', 'overstatement', 'rhetorical_question']].values\n",
        "y_test = df_test[['sarcasm', 'irony', 'satire', 'understatement', 'overstatement', 'rhetorical_question']].values\n",
        "y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHnTGbfrGwQQ",
        "outputId": "cbca40d2-cf30-4dbd-fbb3-903909955730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3467, 6), (1400, 6))"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=y_train.dropna()"
      ],
      "metadata": {
        "id": "LxAgJuiqNIYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **ML with TFIDF**"
      ],
      "metadata": {
        "id": "ksebkraDWYM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn import metrics\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "rf = RandomForestClassifier(class_weight='balanced_subsample')\n",
        "grid_rf = GridSearchCV(rf, {'n_estimators':[300,700], 'max_depth':[7,11]})\n",
        "\n",
        "xgb_classifier = XGBClassifier()\n",
        "grid_xgb = GridSearchCV(xgb_classifier, {'n_estimators':[500,700],\n",
        "                                         'max_depth':[7,11]})\n",
        "\n",
        "lr = LogisticRegressionCV(max_iter=1000)\n",
        "svm = SVC()\n",
        "\n",
        "lr_model = lr.fit(xtrain_tfidf, y_train)\n",
        "rf_model = grid_rf.fit(xtrain_tfidf, y_train)\n",
        "xgb_model = grid_xgb.fit(xtrain_tfidf, y_train)\n",
        "svm_model = svm.fit(x_train_tfidf, y_train)\n",
        "\n",
        "y_pred_lr = lr_model.predict(xtest_tfidf)\n",
        "y_pred_rf = rf_model.predict(xtest_tfidf)\n",
        "y_pred_xgb = xgb_model.predict(xtest_tfidf)\n",
        "y_pred_svm = svm_model.predict(xtest_tfidf)\n",
        "\n",
        "y_pred_lr1 = [1 if prob > 0.5 else 0 for prob in y_pred_lr]\n",
        "y_pred_rf1 = np.where(y_pred_rf > 0.5, 1, 0)\n",
        "y_pred_xgb1 = np.where(y_pred_xgb > 0.5, 1, 0)\n",
        "y_pred_svm1 = np.where(y_pred_svm > 0.5, 1, 0)\n",
        "\n",
        "print(\"F1-Score: LR with tfidf:\", f1_score(y_test, y_pred_lr1 , average=\"macro\"))\n",
        "print(\"F1-Score: RF with tfidf:\", f1_score(y_test, y_pred_rf1 , average=\"macro\"))\n",
        "print(\"F1-Score: XGB with tfidf:\", f1_score(y_test, y_pred_xgb1 , average=\"macro\"))\n",
        "print(\"F1-Score: SVM with tfidf:\", f1_score(y_test, y_pred_svm1 , average=\"macro\"))"
      ],
      "metadata": {
        "id": "VLQmHAEhGBRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ML with BOW**"
      ],
      "metadata": {
        "id": "nvu4EUhXWbLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "rf = RandomForestClassifier(class_weight='balanced_subsample')\n",
        "grid_rf = GridSearchCV(rf, {'n_estimators':[300,700], 'max_depth':[7,11]})\n",
        "\n",
        "xgb_classifier = XGBClassifier()\n",
        "grid_xgb = GridSearchCV(xgb_classifier, {'n_estimators':[500,700],\n",
        "                                         'max_depth':[7,11]})\n",
        "\n",
        "lr = LogisticRegressionCV(max_iter=1000)\n",
        "svm = SVC()\n",
        "\n",
        "lr_model = lr.fit(xtrain_bow, y_train)\n",
        "rf_model = grid_rf.fit(xtrain_bow, y_train)\n",
        "xgb_model = grid_xgb.fit(xtrain_bow, y_train)\n",
        "svm_model = svm.fit(x_train_bow, y_train)\n",
        "\n",
        "y_pred_lr = lr_model.predict(xtest_bow)\n",
        "y_pred_rf = rf_model.predict(xtest_bow)\n",
        "y_pred_xgb = xgb_model.predict(xtest_bow)\n",
        "y_pred_svm = svm_model.predict(xtest_svm)\n",
        "\n",
        "y_pred_lr1 = [1 if prob > 0.5 else 0 for prob in y_pred_lr]\n",
        "y_pred_rf1 = np.where(y_pred_rf > 0.5, 1, 0)\n",
        "y_pred_xgb1 = np.where(y_pred_xgb > 0.5, 1, 0)\n",
        "y_pred_svm1 = np.where(y_pred_svm > 0.5, 1, 0)\n",
        "\n",
        "print(\"F1-Score: LR with BOW:\", f1_score(y_test, y_pred_lr1 , average=\"binary\"))\n",
        "print(\"F1-Score: RF with BOW:\", f1_score(y_test, y_pred_rf1 , average=\"macro\"))\n",
        "print(\"F1-Score: XGB with BOW:\", f1_score(y_test, y_pred_xgb1 , average=\"macro\"))\n",
        "print(\"F1-Score: SVM with svm:\", f1_score(y_test, y_pred_svm1 , average=\"macro\"))"
      ],
      "metadata": {
        "id": "SZMGWj_VGEoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM Methods"
      ],
      "metadata": {
        "id": "OTO-znk3GFSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = df['tweet'].values\n",
        "x_test = df_test['text'].values\n",
        "\n",
        "y_train = df[['sarcasm', 'irony', 'satire', 'understatement', 'overstatement', 'rhetorical_question']].values\n",
        "y_test = df_test[['sarcasm', 'irony', 'satire', 'understatement', 'overstatement', 'rhetorical_question']].values\n",
        "x_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RN8Xs6Qb-BQ",
        "outputId": "19feb1e0-f97d-4b1f-b6f1-020ebba24529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3467,), (3467, 6))"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **LSTM with GloVe**"
      ],
      "metadata": {
        "id": "WmHJvWDZMGAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM, Activation, Dropout, Dense, Input\n",
        "from keras.models import Model\n",
        "\n",
        "vocab_len = len(word_index)\n",
        "emb_dim = 200\n",
        "\n",
        "embedding_layer = Embedding(vocab_len,\n",
        "                            maxlen,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=maxlen,\n",
        "                            trainable=False)\n",
        "\n",
        "#Bi-LSTM\n",
        "model = Sequential([\n",
        "    embedding_layer,\n",
        "  Bidirectional(LSTM(emb_dim, return_sequences=True)),\n",
        "  Dropout(0.5),\n",
        "  Bidirectional(LSTM(emb_dim,)),\n",
        "  Dropout(0.5),\n",
        "  Dense(6, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "'''\n",
        "#LSTM\n",
        "model = Sequential([\n",
        "    embedding_layer,\n",
        "    LSTM(emb_dim, return_sequences=True),\n",
        "    Dropout(0.5),\n",
        "    LSTM(emb_dim,),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "'''\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "#Option 2\n",
        "\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(Embedding(vocab_len, emb_dim, input_len = maxlen, trainable = False, weights=[embedding_matrix]))\n",
        "lstm_model.add(LSTM(128, return_sequences=False))\n",
        "lstm_model.add(Dropout(0.5))\n",
        "lstm_model.add(Dense(1, activation = 'sigmoid'))\n",
        "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(lstm_model.summary())\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "zSMFgxQjGIZe",
        "outputId": "5df06307-b060-4ab2-a248-8acfc7df62ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 200, 200)          2277200   \n",
            "                                                                 \n",
            " bidirectional_15 (Bidirecti  (None, 200, 400)         641600    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 200, 400)          0         \n",
            "                                                                 \n",
            " bidirectional_16 (Bidirecti  (None, 400)              961600    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 400)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 6)                 2406      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,882,806\n",
            "Trainable params: 1,605,606\n",
            "Non-trainable params: 2,277,200\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\n\\n#Option 2\\n\\nlstm_model = Sequential()\\nlstm_model.add(Embedding(vocab_len, emb_dim, input_len = maxlen, trainable = False, weights=[embedding_matrix]))\\nlstm_model.add(LSTM(128, return_sequences=False))\\nlstm_model.add(Dropout(0.5))\\nlstm_model.add(Dense(1, activation = 'sigmoid'))\\nlstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\\nprint(lstm_model.summary())\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(np.expand_dims(x_train,axis=1), y_train, batch_size=64, epochs=10)"
      ],
      "metadata": {
        "id": "yvbRohtlMNcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
        "\n",
        "print(f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "g6r96ZIcMV2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Bidirectional GRUs with Attention**"
      ],
      "metadata": {
        "id": "WkWnrSglXfFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Layer\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "class AttentionLayer(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, step_dim,\n",
        "                 W_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "\n",
        "        \"\"\"\n",
        "        Keras Layer that implements an Attention mechanism for temporal data.\n",
        "        Supports Masking.\n",
        "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
        "        # Input shape\n",
        "            3D tensor with shape: `(samples, steps, features)`.\n",
        "        # Output shape\n",
        "            2D tensor with shape: `(samples, features)`.\n",
        "        :param kwargs:\n",
        "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
        "        The dimensions are inferred based on the output shape of the RNN.\n",
        "        \"\"\"\n",
        "\n",
        "        self.supports_masking = True\n",
        "        self.init = keras.initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = keras.regularizers.get(W_regularizer)\n",
        "        self.b_regularizer = keras.regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = keras.constraints.get(W_constraint)\n",
        "        self.b_constraint = keras.constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight(shape = (input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        self.features_dim = input_shape[-1]\n",
        "\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight(shape = (input_shape[1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "        else:\n",
        "            self.b = None\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        # do not pass the mask to the next layers\n",
        "        return None\n",
        "\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        # TF backend doesn't support it\n",
        "        # eij = K.dot(x, self.W)\n",
        "        # features_dim = self.W.shape[0]\n",
        "        # step_dim = x._keras_shape[1]\n",
        "\n",
        "        features_dim = self.features_dim\n",
        "        step_dim = self.step_dim\n",
        "\n",
        "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
        "                              K.reshape(self.W, (features_dim, 1))),\n",
        "                        (-1, step_dim))\n",
        "\n",
        "        if self.bias:\n",
        "            eij += self.b\n",
        "\n",
        "        eij = K.tanh(eij)\n",
        "\n",
        "        a = K.exp(eij)\n",
        "\n",
        "        # apply mask after the exp. will be re-normalized next\n",
        "        if mask is not None:\n",
        "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        # in some cases especially in the early stages of training the sum may be almost zero\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0],  self.features_dim\n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'step_dim': self.step_dim}\n",
        "        base_config = super(AttentionLayer, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "metadata": {
        "id": "g3rmZhrlGIyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GRU_DIM = 128\n",
        "\n",
        "inp = keras.layers.Input(shape=(maxlen,))\n",
        "x = keras.layers.Embedding(vocab_len, emb_dim, trainable=True)(inp)\n",
        "x = keras.layers.Bidirectional(keras.layers.CuDNNGRU(GRU_DIM, return_sequences=True))(x)\n",
        "x = AttentionLayer(maxlen)(x)\n",
        "x = keras.layers.Dense(GRU_DIM*2, activation='relu')(x)\n",
        "x = keras.layers.Dropout(rate=0.2)(x)\n",
        "x = keras.layers.Dense(GRU_DIM, activation='relu')(x)\n",
        "x = keras.layers.Dropout(rate=0.2)(x)\n",
        "\n",
        "outp = keras.layers.Dense(6, activation='sigmoid')(x)\n",
        "\n",
        "model1 = keras.models.Model(inputs=inp, outputs=outp)\n",
        "\n",
        "model1.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zytiMgY-GJXq",
        "outputId": "26fc1947-3aea-48bb-8a00-dcb662399fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 200)]             0         \n",
            "                                                                 \n",
            " embedding_8 (Embedding)     (None, 200, 200)          2277200   \n",
            "                                                                 \n",
            " bidirectional_14 (Bidirecti  (None, 200, 256)         253440    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " attention_layer_2 (Attentio  (None, 256)              456       \n",
            " nLayer)                                                         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 6)                 774       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,630,558\n",
            "Trainable params: 2,630,558\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model1.fit(x_train, y_train, batch_size=64, epochs=10)"
      ],
      "metadata": {
        "id": "0x4_UIaSX1_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred1 = np.where(y_pred > 0.5, 1, 0)\n",
        "\n",
        "print(f1_score(y_test, y_pred1 , average=\"macro\"))\n",
        "print(classification_report(y_test, y_pred1))"
      ],
      "metadata": {
        "id": "bUS7MgZFX5X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7-xzEjQNGTvg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}